# Research Papers Overview

## Table of Contents
1. **[Mean-Field Multi-Agent Contextual Bandit for Energy-Efficient Resource Allocation in vRANs](#mean-field-multi-agent-contextual-bandit-for-energy-efficient-resource-allocation-in-vrans)**
2. **[Intent-Aware Radio Resource Scheduling in a RAN Slicing Scenario Using Reinforcement Learning](#intent-aware-radio-resource-scheduling-in-a-ran-slicing-scenario-using-reinforcement-learning)**

## Details

### Mean-Field Multi-Agent Contextual Bandit for Energy-Efficient Resource Allocation in vRANs
**Abstract:**
The paper presents a mean-field multi-agent contextual bandit approach for energy-efficient resource allocation in virtualized Radio Access Networks (vRANs). By leveraging mean-field theory and multi-agent systems, the proposed method aims to optimize energy usage while ensuring efficient resource distribution among multiple agents in a vRAN environment.

**Aim:**
The primary aim is to develop a scalable and efficient resource allocation algorithm that reduces energy consumption in vRANs, enhancing overall network performance and sustainability.

**[⬆ Back to Top](#table-of-contents)**

### Intent-Aware Radio Resource Scheduling in a RAN Slicing Scenario Using Reinforcement Learning
**Abstract:**
Network slicing in the radio access network (RAN) domain, known as RAN slicing, demands elasticity, efficient resource sharing, and customization. This paper introduces an intent-aware reinforcement learning method for radio resource scheduling (RRS) in a RAN slicing scenario. The proposed method aims to prevent intent faults by managing radio resources among slices, ensuring fulfillment of slice quality of service (QoS) intents.

**Aim:**
The goal is to enhance the RRS function in RAN slicing by using reinforcement learning to fulfill QoS intents described in service-level agreements (SLAs). The method is evaluated under various network conditions to ensure it outperforms existing baselines.

**Shortcomings:**
- The approach may encounter difficulties in scenarios with highly dynamic network conditions and varying QoS requirements.
- The reinforcement learning method might have high sample complexity and sensitivity to hyperparameters.
- Stability and convergence issues could arise when dealing with continuous state and action spaces.

**[⬆ Back to Top](#table-of-contents)**
